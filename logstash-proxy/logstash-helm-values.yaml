# Install or Upgrade
# helm install beats-proxy elastic/logstash -f values.yaml
#  or
# helm upgrade beats-proxy elastic/logstash -f values.yaml

# Number of service replicas
replicas: 1

# Logstash JMV options
logstashJavaOpts: "-Xmx512m -Xms512m"

# Enable persistent volumes
persistence:
  enabled: true

# Persistent Queue volumes, make sure it matches what Logstash is allowed to write
volumeClaimTemplate:
  accessModes: [ "ReadWriteOnce" ]
  resources:
    requests:
      storage: 1.2Gi

# Service to connect beats to
service:
  name: logstash-proxy-svc
  annotations:
  ports:
  - name: beats-input-ports
    protocol: TCP
    port: 5044
    targetPort: 5044

# Annotations for filebeat autodiscovery to apply logstash module to pod logs
podAnnotations:
  co.elastic.logs/module: logstash

# Extra env variables from secrets to connect to ESS cluster
extraEnvs:
  - name: ELASTIC_CLOUD_ID
    valueFrom:
      secretKeyRef:
        name: cloud-secret
        key: cloud-id
  - name: ELASTIC_CLOUD_AUTH
    valueFrom:
      secretKeyRef:
        name: cloud-secret
        key: cloud-auth
  - name: LOGGING_ELASTIC_CLOUD_ID
    valueFrom:
      secretKeyRef:
        name: logging-cloud-secret
        key: cloud-id
  - name: LOGGING_ELASTIC_CLOUD_AUTH
    valueFrom:
      secretKeyRef:
        name: logging-cloud-secret
        key: cloud-auth

# Logstash config files
logstashConfig:
  logstash.yml: |
    # Listener on all interfaces
    http.host: 0.0.0.0

    # Turn on collector push monitoring
    xpack.monitoring.enabled: true
    xpack.monitoring.elasticsearch.cloud_id: "${LOGGING_ELASTIC_CLOUD_ID}"
    xpack.monitoring.elasticsearch.cloud_auth: "${LOGGING_ELASTIC_CLOUD_AUTH}"


    # Persistent queue settings

    # Turn on to write durably to disk, i.e. fsync every message
    # otherwise it fsyncs every 1024 messages by default and risk a loss of data
    # if the pod crashes
    queue.checkpoint.writes: 1

    # Specify persisted to enable persistent queues. By default, persistent
    # queues are disabled (default: queue.type: memory).
    queue.type: persisted

    # The maximum size of a queue page in bytes. The queue data consists of append-only files called "pages".
    # The default size is 64mb. Changing this value is unlikely to have performance benefits.
    # queue.page_capacity: 0

    # Specify true if you want Logstash to wait until the persistent queue is drained before shutting down.
    # The amount of time it takes to drain the queue depends on the number of events that have accumulated in the queue.
    # Therefore, you should avoid using this setting unless the queue, even when full, is relatively small and can be drained quickly.
    queue.drain: true

    # The maximum number of events that are allowed in the queue. The default is 0 (unlimited).
    # queue.max_events: 0

    # The total capacity of the queue in number of bytes. The default is 1024mb (1gb).
    # Make sure the capacity of your disk drive is greater than the value you specify here.
    # Make sure the queue size is less or equal to the persistent volume size.
    queue.max_bytes: 1gb


# Logstash pipeline
logstashPipeline:
  logstash.conf: |
    input {
      beats {
        port => 5044
      }
    }

    output {
      if [@metadata][beat] == "apm" {

        # APM event indexing
        elasticsearch {
          cloud_auth => "${ELASTIC_CLOUD_AUTH}"
          cloud_id => "${ELASTIC_CLOUD_ID}"
          manage_template => "false"
          index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{[processor][event]}"
        }
      } else {

          # Beats event indexing
          elasticsearch {
            cloud_auth => "${ELASTIC_CLOUD_AUTH}"
            cloud_id => "${ELASTIC_CLOUD_ID}"
            manage_template => "false"
            index => "%{[@metadata][beat]}-%{[@metadata][version]}"
        }
      }
    }
